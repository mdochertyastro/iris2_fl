{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE FOR SINGLE RASTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ยง0 - Read-in and set-up\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 - file read-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your file iris2model.sav contains an inversion of a single raster and will be returned as a numpy.record...\n",
      "...with the required structure\n"
     ]
    }
   ],
   "source": [
    "from sav_extract import sav_extract\n",
    "filename='iris2model.sav'\n",
    "iris2model=sav_extract(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 - Initial data read-in and trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris_cal has successfully been trimmed to (217, 183, 32)\n"
     ]
    }
   ],
   "source": [
    "from data_extract import tag_extract, kpeak_ind_extract, trimmed_rows, data_trim\n",
    "\n",
    "wavelength  = tag_extract(iris2model,'wl') # need this one first\n",
    "iris_cal    = tag_extract(iris2model,'iris_cal') # then this one to get trimmed rows from kpeak frame\n",
    "\n",
    "kpeak_ind   = kpeak_ind_extract(wavelength) # isolate the wavelength index closest to Mg II k peak\n",
    "frame       = iris_cal[kpeak_ind,...] # create a frame at this peak wavelength, where FL is most visible\n",
    "trimmed_rows= trimmed_rows(frame) # cuts FOV to only include observed data, not zeros at top and bottom (returns list of top and bottom row)\n",
    "\n",
    "del frame # it has served its purpose to get trimmed rows, now delete to save confusion pre-trim\n",
    "del wavelength\n",
    "\n",
    "iris_cal    = data_trim(iris_cal, trimmed_rows,'iris_cal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 - Initial frame creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame=iris_cal[kpeak_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ยง1 - Frame cleaning function list\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - Slit row extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def slit_row_extract(frame):\n",
    "    '''\n",
    "    Extract the index of the row with the slit in it from monochromatic image.\n",
    "    Works by getting the row index of the min val in each col and taking the most common\n",
    "    row value from that list\n",
    "    '''\n",
    "    slit_rows=[]\n",
    "    for col in range(frame.shape[1]):\n",
    "        slit_rows.append(np.argmin(frame[:,col]))\n",
    "    slit_row=int(stats.mode(slit_rows)[0])\n",
    "    return slit_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - Threshold extraction function (using hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # explicitly state package dependencies for each sep function\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "def thresh_extract(frame,slit_row):\n",
    "    '''\n",
    "    Extract flat threshold frame for filament sep from k3 monochromatic frame.\n",
    "    It does this by raising slit vals to a max value so the first trough of histogram \n",
    "    is roughly the threshold between filamenty and quiet sun.\n",
    "    (Only tested for quiet sun filament obs as of 21/09/2020)\n",
    "    '''\n",
    "    ### raise slit vals to max for hist peaks\n",
    "    frame[slit_row,:]=np.amax(frame) \n",
    "    frame[slit_row-1,:]=np.amax(frame)\n",
    "\n",
    "    ### then do find peaks for thresh here:\n",
    "    frame_linear=np.reshape(frame,-1)\n",
    "    bin_number=int(len(frame_linear)/80) # 80 decided empirically to give consistently good peaks\n",
    "    hist,bins = np.histogram(frame_linear, bins = bin_number) # iteratively decided on 70 bins\n",
    "    bin_centres = 0.5*(bins[1:]+bins[:-1])\n",
    "\n",
    "    peaks, _ = find_peaks(-hist) # find troughs\n",
    "    index=peaks[0] # since bin size is so big, first trough corresponds to post-FL dip.\n",
    "    thresh=bin_centres[index] \n",
    "    frame[frame>thresh]=0\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 - Binary mask extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import medfilt\n",
    "\n",
    "def bin_mask_extract(frame,slit_row=None):\n",
    "    '''\n",
    "    Extracts binary mask array-like 1s for filament, 0s for quiet sun from post-thresh frame.\n",
    "    It does this using a basic median filter that cleans out rough edges of post-thresh frame.\n",
    "    For border creation, don't give slit_row keyword (COSMETIC)\n",
    "    For index sep and further data reduction, give slit_row keyword (DATA REDUCTION)\n",
    "    '''\n",
    "    bin_mask=np.where(frame>0,1,0)\n",
    "    if slit_row is None: # COSMETIC no slits nan'd to create line border\n",
    "        bin_mask=medfilt(bin_mask,5) \n",
    "        return bin_mask # COSMETIC\n",
    "    else:\n",
    "        # DATA REDUCTION slit rows are nan'd to stop slit row values (which are neither FL or QS) being wronlgy counted as such\n",
    "        # need to give slit row value as explicit argument when calling function\n",
    "        bin_mask[slit_row,:]=100 \n",
    "        bin_mask[slit_row-1,:]=100\n",
    "        bin_mask=np.where(bin_mask>1,np.nan,bin_mask)\n",
    "        bin_mask=medfilt(bin_mask,5) \n",
    "        return bin_mask # Further DATA REDUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 - Mask border extraction function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "def get_all_boundary_edges(bool_img):\n",
    "    '''\n",
    "    Get a list of all edges\n",
    "    (where the value changes from 'True' to 'False') in the 2D image.\n",
    "    Return the list as indices of the image.\n",
    "    '''\n",
    "    ij_boundary = []\n",
    "    ii, jj = np.nonzero(bool_img)\n",
    "    for i, j in zip(ii, jj):\n",
    "        # North\n",
    "        if j == bool_img.shape[1]-1 or not bool_img[i, j+1]:\n",
    "            ij_boundary.append(np.array([[i, j+1],\n",
    "                                         [i+1, j+1]]))\n",
    "        # East\n",
    "        if i == bool_img.shape[0]-1 or not bool_img[i+1, j]:\n",
    "            ij_boundary.append(np.array([[i+1, j],\n",
    "                                         [i+1, j+1]]))\n",
    "        # South\n",
    "        if j == 0 or not bool_img[i, j-1]:\n",
    "            ij_boundary.append(np.array([[i, j],\n",
    "                                         [i+1, j]]))\n",
    "        # West\n",
    "        if i == 0 or not bool_img[i-1, j]:\n",
    "            ij_boundary.append(np.array([[i, j],\n",
    "                                         [i, j+1]]))\n",
    "    if not ij_boundary:\n",
    "        return np.zeros((0, 2, 2))\n",
    "    else:\n",
    "        return np.array(ij_boundary)\n",
    "\n",
    "def close_loop_boundary_edges(xy_boundary, clean=True):\n",
    "    '''\n",
    "    Connect all edges defined by 'xy_boundary' to closed \n",
    "    boundary lines.\n",
    "    If not all edges are part of one surface return a list of closed \n",
    "    boundaries is returned (one for every object).\n",
    "    '''\n",
    "    boundary_loop_list = []\n",
    "    while xy_boundary.size != 0:\n",
    "        # Current loop\n",
    "        xy_cl = [xy_boundary[0, 0], xy_boundary[0, 1]]  # Start with first edge\n",
    "        xy_boundary = np.delete(xy_boundary, 0, axis=0)\n",
    "\n",
    "        while xy_boundary.size != 0:\n",
    "            # Get next boundary edge (edge with common node)\n",
    "            ij = np.nonzero((xy_boundary == xy_cl[-1]).all(axis=2))\n",
    "            if ij[0].size > 0:\n",
    "                i = ij[0][0]\n",
    "                j = ij[1][0]\n",
    "            else:\n",
    "                xy_cl.append(xy_cl[0])\n",
    "                break\n",
    "\n",
    "            xy_cl.append(xy_boundary[i, (j + 1) % 2, :])\n",
    "            xy_boundary = np.delete(xy_boundary, i, axis=0)\n",
    "\n",
    "        xy_cl = np.array(xy_cl)\n",
    "\n",
    "        boundary_loop_list.append(xy_cl)\n",
    "\n",
    "    return boundary_loop_list\n",
    "\n",
    "def plot_world_outlines(bool_img, ax=None, **kwargs):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    ij_boundary = get_all_boundary_edges(bool_img=bool_img)\n",
    "    xy_boundary = ij_boundary - 0.5\n",
    "    xy_boundary = close_loop_boundary_edges(xy_boundary=xy_boundary)\n",
    "    cl = LineCollection(xy_boundary, **kwargs)\n",
    "    ax.add_collection(cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ยง2 - Data reduction function list\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Bad pixel extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def non_finite_pix_extract(uncertainty): # bin_mask it just to get a nnice 2D array for pix yuple indices - ideally could do this straight from uncertainty data cube, will try after\n",
    "    '''\n",
    "    Iterates pix by pix basis through temp uncertainty and makes a list of tuples with non finite uncertainty.\n",
    "    These pixels should be omitted before pix region assignment.\n",
    "    (can do only for temp as all model variables have same (bad) fitting for each pixel)\n",
    "    '''\n",
    "    bad_pix=[]\n",
    "    local_temp_unc=uncertainty[0,...]\n",
    "    test_array=np.zeros(local_temp_unc.shape[0])\n",
    "\n",
    "    for tuple_index,_ in np.ndenumerate(local_temp_unc[0,...]): # goes through pix index pix by pix in 2d\n",
    "        temp_ltau=local_temp_unc[:,tuple_index[0],tuple_index[1]] #for all values of ltau but single pix\n",
    "        finite_test_array=np.isfinite(temp_ltau,test_array)\n",
    "        if np.any(finite_test_array==0):\n",
    "            bad_pix.append(tuple_index)       \n",
    "    return bad_pix\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Pixel region assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pix_region_assign(bin_mask):\n",
    "    '''\n",
    "    Takes input of binary mask with slit values as nans and returns two lists as index tuples \n",
    "    for pixels belonging to fl and qs regions (in that order) only if all pix are accounted for.\n",
    "    Slit pixels are added to a seperate list but not returned. This is created to ensure all \n",
    "    pixels of bin mask are accounted for but serve no further purpose.\n",
    "    '''\n",
    "    fl_pix=[]\n",
    "    qs_pix=[]\n",
    "    slit_pix=[]\n",
    "    for pix_ind, pix_val in np.ndenumerate(bin_mask):\n",
    "        if pix_val==0:\n",
    "            qs_pix.append(pix_ind)\n",
    "        if pix_val==1:\n",
    "            fl_pix.append(pix_ind)\n",
    "        if np.isnan(pix_val)==True:\n",
    "            slit_pix.append(pix_ind)\n",
    "\n",
    "    if len(fl_pix+qs_pix+slit_pix)==len(np.reshape(bin_mask,-1)):\n",
    "        print('All binary mask pixels successfully accounted for...')\n",
    "        return fl_pix,qs_pix        \n",
    "    else:\n",
    "        print('Not all binary pixels are accounted for...')\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Data and unc mean (removing bad fits - NEW METHOD) - *IMPORANT*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def data_mean_extract(model_dat_cube,pixels):\n",
    "    '''\n",
    "    Creates arrays for model means and their uncertainties for QS/Fl seperately\n",
    "    (model is either temp or ne, pixels is eiher qs or fl list)\n",
    "    '''\n",
    "    model_sum=np.zeros(model_dat_cube.shape[0]) # makes zero array like ltau\n",
    "    for tuple_index in pixels:\n",
    "        model_ltau=model_dat_cube[:,tuple_index[0],tuple_index[1]] #for all values of ltau but single pix\n",
    "        print(type(model_ltau),model_ltau.shape)\n",
    "        np.isfinite()\n",
    "        # want to skip pixels that have nans or infs\n",
    "        \n",
    "        model_ltau=np.nan_to_num(model_ltau,nan=0,posinf=0) #some uncs were 'inf' which messed up the sum, so for these I have removed them.\n",
    "        model_sum=model_sum+model_ltau\n",
    "    model_mean=model_sum/len(pixels)    \n",
    "    return model_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing numpy.isfinite() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "array_inf=np.array([1,2,3,4,5,np.nan,6,7,np.inf,9])\n",
    "array_fin=np.array([1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.isfinite(array_inf)\n",
    "x=np.isfinite(array_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(x==False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(y==False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full pipeline for test\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main model variables assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ltau has successfully been trimmed to (37,)\n",
      "model has successfully been trimmed to (4, 37, 183, 32)\n",
      "uncertainty has successfully been trimmed to (4, 37, 183, 32)\n"
     ]
    }
   ],
   "source": [
    "ltau        = tag_extract(iris2model,'ltau')\n",
    "ltau        = data_trim(ltau,trimmed_rows,'ltau')\n",
    "\n",
    "model       = tag_extract(iris2model,'model')\n",
    "model       = data_trim(model,trimmed_rows,'model')\n",
    "\n",
    "uncertainty = tag_extract(iris2model,'uncertainty')\n",
    "uncertainty = data_trim(uncertainty,trimmed_rows,'uncertainty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp, temp_unc= model[0,...],  uncertainty[0,...]\n",
    "ne,   ne_unc  = model[3,...],  uncertainty[3,...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline for data reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All binary mask pixels successfully accounted for...\n"
     ]
    }
   ],
   "source": [
    "slit_row=slit_row_extract(frame)\n",
    "thresh_frame=thresh_extract(frame,slit_row)\n",
    "bin_mask_slit=bin_mask_extract(frame,slit_row=slit_row)\n",
    "fl_pix,qs_pix=pix_region_assign(bin_mask_slit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match\n",
      "[1, 2, 3, 5]\n"
     ]
    }
   ],
   "source": [
    "coords=[1,2,3,4,5]\n",
    "\n",
    "test_val=4\n",
    "\n",
    "if test_val in coords:\n",
    "    print('match')\n",
    "    coords.remove(test_val)\n",
    "    print(coords)\n",
    "else:\n",
    "    print('no match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_val in coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coords.remove(2)\n",
    "coords.remove(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 5]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_pix=non_finite_pix_extract(uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bad_pix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-c9855fab35f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_mask_slit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lower'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtuple_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbad_pix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtuple_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m's'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bad_pix' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax=plt.subplots(figsize=(10,10))\n",
    "\n",
    "cmap = plt.get_cmap('jet_r', 2)\n",
    "ax.set_facecolor('k')\n",
    "ax.imshow(bin_mask_slit,aspect='auto',origin='lower',cmap=cmap)\n",
    "\n",
    "for tuple_index in bad_pix:\n",
    "    ax.plot(tuple_index[1],tuple_index[0],'s',color='w',ms=5)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iris2_venv",
   "language": "python",
   "name": "iris2_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
